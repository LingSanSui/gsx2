import gc
import hashlib
import logging
import time
import traceback
from typing import Any

import datasets
import torch
from hivemind.dht import DHT
from hivemind.utils import get_dht_time
from trl import GRPOConfig, GRPOTrainer

from hivemind_exp.debug_utils import print_system_info
from hivemind_exp.dht_utils import (
    ROUND_STAGE_NUMBER_KEY,
    get_dht_value,
    get_round_and_stage,
    leaderboard_key,
    node_outputs_key,
    rewards_key,
)
from hivemind_exp.hivemind_utils import HivemindNode, StageData
from hivemind_exp.name_utils import get_name_from_peer_id


MAX_TRAIN_FAILS = 5
CADENCE_OF_UPDATE_STEPS = 4


class HivemindGRPOTrainer:
    """
    GRPOTrainerçš„å­ç±»ï¼Œé€šè¿‡å°†ä¸­é—´ç»“æœå‘å¸ƒåˆ°è¿æ¥çš„Hivemind DHTæ¥å®ç°å¤šé˜¶æ®µGRPOè®­ç»ƒã€‚
    è¯¥ç±»è´Ÿè´£åè°ƒå¤šä¸ªèŠ‚ç‚¹ä¹‹é—´çš„è®­ç»ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬åè°ƒè€…èŠ‚ç‚¹å’Œè·Ÿéšè€…èŠ‚ç‚¹çš„ä¸åŒè¡Œä¸ºã€‚
    """

    class PublishingGRPOTrainer(GRPOTrainer):
        """
        å†…éƒ¨GRPOTrainerå­ç±»ï¼Œè´Ÿè´£å°†è®­ç»ƒç»“æœå‘å¸ƒåˆ°DHTç½‘ç»œã€‚
        è¯¥ç±»æ‰©å±•äº†æ ‡å‡†GRPOTrainerï¼Œæ·»åŠ äº†å‘å¸ƒå¥–åŠ±ã€è¾“å‡ºå’Œæ’è¡Œæ¦œåˆ°åˆ†å¸ƒå¼å“ˆå¸Œè¡¨çš„åŠŸèƒ½ã€‚
        """
        def __init__(
            self,
            node: HivemindNode,  # HivemindèŠ‚ç‚¹å®ä¾‹
            dht: DHT,            # åˆ†å¸ƒå¼å“ˆå¸Œè¡¨å®ä¾‹
            tokenizer,           # åˆ†è¯å™¨
            logger,              # æ—¥å¿—è®°å½•å™¨
            **kwargs,            # å…¶ä»–å‚æ•°ä¼ é€’ç»™çˆ¶ç±»
        ):
            """
            åˆå§‹åŒ–PublishingGRPOTrainer
            
            å‚æ•°:
                node: HivemindèŠ‚ç‚¹å®ä¾‹ï¼ŒåŒ…å«èŠ‚ç‚¹èº«ä»½å’ŒçŠ¶æ€ä¿¡æ¯
                dht: åˆ†å¸ƒå¼å“ˆå¸Œè¡¨å®ä¾‹ï¼Œç”¨äºå­˜å‚¨å’Œæ£€ç´¢åˆ†å¸ƒå¼è®­ç»ƒæ•°æ®
                tokenizer: ç”¨äºå¤„ç†æ–‡æœ¬çš„åˆ†è¯å™¨
                logger: æ—¥å¿—è®°å½•å™¨
                **kwargs: ä¼ é€’ç»™çˆ¶ç±»GRPOTrainerçš„å…¶ä»–å‚æ•°
            """
            self.node = node
            self.dht = dht
            self.logger = logger
            self.stage_rewards = 300.0  # é˜¶æ®µå¥–åŠ±ç´¯è®¡å€¼
            super().__init__(processing_class=tokenizer, **kwargs)

        def publish_leaderboard(self):
            """
            å‘å¸ƒå½“å‰è½®æ¬¡å’Œé˜¶æ®µçš„æ’è¡Œæ¦œåˆ°DHT
            æ ¹æ®æ‰€æœ‰èŠ‚ç‚¹çš„å¥–åŠ±å€¼åˆ›å»ºæ’åºåçš„æ’è¡Œæ¦œå¹¶å­˜å‚¨åˆ°åˆ†å¸ƒå¼å“ˆå¸Œè¡¨ä¸­
            """
            r, s = self.node.round_num, self.node.stage_num
            curr_rewards: dict[str, Any] | None = get_dht_value(
                self.dht, key=rewards_key(r, s), latest=True
            )
            if curr_rewards:
                # åˆ›å»º(èŠ‚ç‚¹é”®, å¥–åŠ±å€¼)å¯¹çš„æ’åºåˆ—è¡¨
                leaderboard = list(
                    sorted(
                        curr_rewards.items(), key=lambda t: (t[1], t[0]), reverse=True
                    )
                )
                self.dht.store(
                    key=leaderboard_key(r, s),
                    value=leaderboard,
                    expiration_time=get_dht_time() + self.node.out_expiration,
                )
            else:
                self.logger.info(f"æ— æ³•è·å–è½®æ¬¡ {r} é˜¶æ®µ {s - 1} çš„å¥–åŠ±å€¼")

        def compute_loss(self, model, inputs, *args, **kwargs):
            """
            è®¡ç®—æ¨¡å‹æŸå¤±å¹¶å®šæœŸå°†èŠ‚ç‚¹è¾“å‡ºå’Œå¥–åŠ±å‘å¸ƒåˆ°DHT
            
            
            å‚æ•°:
                model: è¦è®­ç»ƒçš„æ¨¡å‹
                inputs: æ¨¡å‹è¾“å…¥æ•°æ®
                *args, **kwargs: ä¼ é€’ç»™çˆ¶ç±»compute_lossæ–¹æ³•çš„å…¶ä»–å‚æ•°
                
            è¿”å›:
                è®¡ç®—å¾—åˆ°çš„æŸå¤±å€¼
            """
            loss = super().compute_loss(model, inputs, *args, **kwargs)
            # å¥–åŠ±å‡½æ•°å¿…é¡»ä¿å­˜node.outputså’Œnode.rewards!
            # è¿™é‡Œçš„ä»£ç è´Ÿè´£åœ¨é€‚å½“çš„æ—¶é—´å°†æ•°æ®å‘å¸ƒåˆ°DHT
            # æ¯Næ­¥å‘å¸ƒä¸€æ¬¡æ•°æ®åˆ°DHT
            self.logger.info(
                f"  âœ…âœ…âœ…âœ…âœ…âœ…------âœ…âœ…âœ…âœ…âœ… "
            )
            if self.state.global_step % CADENCE_OF_UPDATE_STEPS == 0:
                question = self.node.outputs["question"]
                q_hash = hashlib.md5(question.encode()).hexdigest()

                value = (time.time(), self.node.outputs)
                self.logger.info(
                    f"  --->>   keyå€¼ä¸º             {node_outputs_key(self.node)}"
                )
                self.logger.info(
                    f"  --->>   subkeyå€¼ä¸º          {q_hash}"
                )
                self.logger.info(
                    f"  --->>   valueå€¼ä¸º           {value}"
                )
                self.logger.info(
                    f"  --->>   expiration_timeå€¼ä¸º {get_dht_time() + self.node.out_expiration}"
                )
                self.dht.store(
                    key=node_outputs_key(self.node),
                    subkey=q_hash,
                    value=value,
                    expiration_time=get_dht_time() + self.node.out_expiration,
                )
                self.node.put_stage_outputs(
                    self.node.round_num, self.node.stage_num, q_hash, value
                )

                # ç´¯åŠ æœ€æ–°çš„å¥–åŠ±å€¼
                self.stage_rewards += sum(self.node.rewards)
                
                self.logger.info(
                    f"  --->>   keyå€¼ä¸º             {rewards_key(self.node.round_num, self.node.stage_num)}"
                )
                self.logger.info(
                    f"  --->>   subkeyå€¼ä¸º          {self.node.key}"
                )
                self.logger.info(
                    f"  --->>   valueå€¼ä¸º            {self.stage_rewards}"
                )
                self.logger.info(
                    f"  --->>   expiration_timeå€¼ä¸º {get_dht_time() + self.node.out_expiration}"
                )
                self.logger.info(
                    f"  âœ…âœ…âœ…âœ…âœ…âœ…------âœ…âœ…âœ…âœ…âœ… "
                )
                self.dht.store(
                    key=rewards_key(self.node.round_num, self.node.stage_num),
                    subkey=self.node.key,
                    value=self.stage_rewards,
                    expiration_time=get_dht_time() + self.node.out_expiration,
                )
            if self.node.is_coordinator:
                self.publish_leaderboard()

            return loss

    def __init__(
        self,
        node: HivemindNode,      # HivemindèŠ‚ç‚¹å®ä¾‹
        dht: DHT,                # åˆ†å¸ƒå¼å“ˆå¸Œè¡¨å®ä¾‹
        stage_data: StageData,   # è®­ç»ƒé˜¶æ®µæ•°æ®
        config: GRPOConfig,      # GRPOé…ç½®
        model,                   # è¦è®­ç»ƒçš„æ¨¡å‹
        tokenizer,               # åˆ†è¯å™¨
        log_tag=None,            # æ—¥å¿—æ ‡ç­¾
        **kwargs,                # å…¶ä»–å‚æ•°
    ):
        """
        åˆå§‹åŒ–HivemindGRPOTrainer
        
        
        å‚æ•°:
            node: HivemindèŠ‚ç‚¹å®ä¾‹ï¼Œå®šä¹‰èŠ‚ç‚¹èº«ä»½å’Œè§’è‰²ï¼ˆåè°ƒè€…æˆ–è·Ÿéšè€…ï¼‰
            dht: åˆ†å¸ƒå¼å“ˆå¸Œè¡¨å®ä¾‹ï¼Œç”¨äºèŠ‚ç‚¹é—´é€šä¿¡å’Œæ•°æ®å…±äº«
            stage_data: åŒ…å«è®­ç»ƒé˜¶æ®µä¿¡æ¯çš„StageDataå®ä¾‹
            config: GRPOè®­ç»ƒé…ç½®
            model: è¦è®­ç»ƒçš„æ¨¡å‹
            tokenizer: ç”¨äºå¤„ç†æ–‡æœ¬çš„åˆ†è¯å™¨
            log_tag: å¯é€‰çš„æ—¥å¿—æ ‡ç­¾ï¼Œé»˜è®¤ä½¿ç”¨èŠ‚ç‚¹é”®
            **kwargs: å…¶ä»–å‚æ•°
        """
        # å•ä¸ªåè°ƒè€…è´Ÿè´£é€’å¢è½®æ¬¡å’Œé˜¶æ®µç¼–å·
        # TODO(lou): å…è®¸é€‰æ‹©ä¸åŒçš„åè°ƒè€…ï¼Ÿ
        self.node = node
        self.dht = dht

        self.stage_data = stage_data

        self.config = config
        self.config.dataloader_num_workers=0  # é»˜è®¤å€¼: 8+
        assert self.config.output_dir
        self.config.output_dir += f"-{get_name_from_peer_id(self.node.key, True)}"  # TODO: åœ¨æ›´åˆé€‚çš„ä½ç½®æ·»åŠ åŠ¨ç‰©åç§°åˆ°ä¿å­˜è·¯å¾„
        self.model = model
        self.tokenizer = tokenizer
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token

        if not log_tag:
            log_tag = self.node.key

        self.logger = logging.getLogger(f"{__name__}:{log_tag}")

    def wait_for(self, result_fn=lambda: None, interval=10, timeout=30):
        """
        ç­‰å¾…å‡½æ•°è¿”å›éNoneç»“æœæˆ–è¶…æ—¶
        
        
        å‚æ•°:
            result_fn: è¦æ‰§è¡Œçš„å‡½æ•°ï¼Œåº”è¿”å›ç»“æœæˆ–None
            interval: é‡è¯•é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
            timeout: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
            
        è¿”å›:
            å‡½æ•°çš„ç»“æœï¼Œå¦‚æœè¶…æ—¶å¯èƒ½ä¸ºNone
        """
        start_time = time.monotonic()
        while time.monotonic() - start_time < timeout:
            result = result_fn()
            if result is None:
                time.sleep(interval)
            else:
                break

        return result

    def train_stages(self, round_num, start_stage, is_coordinator):
        """
        è®­ç»ƒæŒ‡å®šè½®æ¬¡çš„å¤šä¸ªé˜¶æ®µ
        
        
        å‚æ•°:
            round_num: å½“å‰è®­ç»ƒè½®æ¬¡
            start_stage: å¼€å§‹è®­ç»ƒçš„é˜¶æ®µç´¢å¼•
            is_coordinator: æ˜¯å¦ä¸ºåè°ƒè€…èŠ‚ç‚¹
        """
        # TODO: éœ€è¦æ·»åŠ æ£€æŸ¥ç‚¹åŠ è½½åŠŸèƒ½
        self.node.round_num = round_num
        for i, stage in enumerate(self.stage_data.stages[start_stage:]):
            stage_num = start_stage + i
            self.node.stage_num = stage_num

            if is_coordinator:
                self.dht.store(
                    key=ROUND_STAGE_NUMBER_KEY,
                    value=(self.node.round_num, stage_num),
                    expiration_time=get_dht_time() + self.node.out_expiration,
                )

            self.logger.info(f"ğŸ“ˆ è®­ç»ƒè½®æ¬¡: {round_num} é˜¶æ®µ: {stage_num}")
            train_dataset, test_dataset = stage.datasets_fn(round_num, stage_num)
            kwargs = {
                "model": self.model,
                "args": self.config,
                "reward_funcs": stage.reward_funcs,
                "train_dataset": train_dataset,
                "eval_dataset": test_dataset,
            }
            trainer = HivemindGRPOTrainer.PublishingGRPOTrainer(
                self.node, self.dht, self.tokenizer, self.logger, **kwargs
            )
            self.train_and_save(trainer, train_dataset)
            self.logger.info(
                f"ğŸ“‰ å®Œæˆè®­ç»ƒè½®æ¬¡: {round_num} é˜¶æ®µ: {stage_num}"
            )

        # å¦‚æœéœ€è¦ï¼Œæ¨é€æ¨¡å‹åˆ°HF hub
        # TODO: æ·»åŠ é¢å¤–çš„é€»è¾‘æ£€æŸ¥æ˜¯å¦æä¾›äº†è®¿é—®ä»¤ç‰Œå’ŒHFç”¨æˆ·å
        if self.config.push_to_hub_token is not None:
            self.logger.info("æ­£åœ¨æ¨é€æ¨¡å‹åˆ°Hugging Face Hub...")
            try:
                trainer.push_to_hub(
                    tags=[
                        "rl-swarm",
                        "grpo",
                        "gensyn",
                        f"I am {get_name_from_peer_id(self.node.key)}",
                    ]
                )
                time.sleep(1)
            except Exception:
                self.logger.info(
                    "æ¨é€æ¨¡å‹åˆ°Hugging Face Hubå¤±è´¥ã€‚å½“æ‚¨å®Œæˆè®­ç»ƒåï¼Œè¯·å°è¯•æŒ‰ç…§ä»¥ä¸‹è¯´æ˜æ‰‹åŠ¨æ¨é€ï¼šhttps://huggingface.co/docs/hub/en/models-uploading"
                )

        self.cleanup()

    def cleanup(self):
        """
        æ¸…ç†å„ç§ç¼“å­˜ï¼Œé‡Šæ”¾å†…å­˜èµ„æº
        åŒ…æ‹¬åƒåœ¾å›æ”¶ã€GPUç¼“å­˜æ¸…ç†å’ŒèŠ‚ç‚¹é˜¶æ®µç¼“å­˜æ¸…ç†
        """
        # æ¸…ç†å„ç§é˜¶æ®µç¼“å­˜
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
        if torch.backends.mps.is_available():  # type: ignore
            torch.mps.empty_cache()  # type: ignore
        try:
            if torch.xpu.is_available():  # type: ignore
                torch.xpu.empty_cache()  # type: ignore
        except AttributeError:
            pass

        self.node.clear_stage_cache()

    def train_and_save(self, trainer, train_dataset):
        """
        æ‰§è¡Œè®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹å’ŒæŒ‡æ ‡
        
        
        å‚æ•°:
            trainer: è®­ç»ƒå™¨å®ä¾‹
            train_dataset: è®­ç»ƒæ•°æ®é›†
        """
        for num_fails in range(MAX_TRAIN_FAILS):
            try:
                train_result = trainer.train()
                break
            except (BlockingIOError, EOFError) as e:
                self.logger.warning(f"DHT IPCé”™è¯¯: {e}. é‡æ–°å¼€å§‹è®­ç»ƒ...")
                self.cleanup()  # æ¸…ç†GPU/ç¼“å­˜
                time.sleep(5)
                continue

        # è®°å½•å¹¶ä¿å­˜æŒ‡æ ‡
        metrics = train_result.metrics
        metrics["train_samples"] = len(train_dataset)
        trainer.log_metrics("train", metrics)
        trainer.save_metrics("train", metrics)
        trainer.save_state()

        self.logger.info("æ­£åœ¨ä¿å­˜æ¨¡å‹")
        trainer.model.config.use_cache = True
        trainer.save_model(self.config.output_dir)
        self.logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ° {self.config.output_dir}")
        assert self.config.distributed_state
        self.config.distributed_state.wait_for_everyone()  # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹åŠ è½½å®Œæˆ

        self.tokenizer.save_pretrained(self.config.output_dir)
        self.logger.info(f"åˆ†è¯å™¨å·²ä¿å­˜åˆ° {self.config.output_dir}")

    def get_round_and_stage(self):
        """
        ä»DHTè·å–å½“å‰è½®æ¬¡å’Œé˜¶æ®µ
        
        è¿”å›:
            å½“å‰è½®æ¬¡å’Œé˜¶æ®µçš„å…ƒç»„ (round_num, stage_num)
        """
        return get_round_and_stage(self.dht)

    def coordinator_train(self):
        """
        åè°ƒè€…èŠ‚ç‚¹çš„è®­ç»ƒæ–¹æ³•
        è´Ÿè´£å¯åŠ¨æ–°çš„è®­ç»ƒè½®æ¬¡å¹¶æ›´æ–°DHTä¸­çš„è½®æ¬¡å’Œé˜¶æ®µä¿¡æ¯
        """
        round_num = 0
        start_time = time.monotonic()
        while (
            round_num < self.stage_data.max_rounds
            and time.monotonic() - start_time < self.stage_data.train_timeout
        ):
            self.logger.info(f"ğŸ¤– å¼€å§‹æ–°è½®æ¬¡: {round_num}")

            _ = self.dht.get_visible_maddrs(latest=True)
            self.train_stages(round_num, 0, is_coordinator=True)

            round_num += 1
            if round_num == self.stage_data.max_rounds:
                return

        self.logger.info("è®­ç»ƒè¶…æ—¶ï¼")

    def follower_train(
        self, check_interval=5.0, log_timeout=10.0, max_check_interval=30.0
    ):
        """
        è·Ÿéšè€…èŠ‚ç‚¹çš„è®­ç»ƒæ–¹æ³•
        
        å®šæœŸæ£€æŸ¥DHTä¸­çš„è½®æ¬¡å’Œé˜¶æ®µä¿¡æ¯ï¼Œå¹¶åŠ å…¥å½“å‰æ´»è·ƒçš„è®­ç»ƒè½®æ¬¡
        
        å‚æ•°:
            check_interval: æ£€æŸ¥DHTçš„åˆå§‹é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
            log_timeout: æ—¥å¿—è®°å½•è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_check_interval: æœ€å¤§æ£€æŸ¥é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
        """
        done_rounds = set()
        start_time = time.monotonic()
        fetch_log_time = start_time
        check_backoff = (
            check_interval  # å¯¹å·²å®Œæˆè½®æ¬¡ä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥
        )
        while time.monotonic() - start_time < self.stage_data.train_timeout:
            curr_time = time.monotonic()
            _ = self.dht.get_visible_maddrs(latest=True)

            # è·å–å½“å‰è½®æ¬¡å’Œé˜¶æ®µ
            try:
                round_num, stage = self.get_round_and_stage()
            except Exception as e:
                if curr_time - fetch_log_time > log_timeout:
                    self.logger.debug(
                        f"æ— æ³•è·å–è½®æ¬¡å’Œé˜¶æ®µä¿¡æ¯: {e}. å°†åœ¨ {check_interval}ç§’åé‡è¯•ã€‚"
                    )
                    fetch_log_time = curr_time

                time.sleep(check_interval)
                continue

            if round_num not in done_rounds:
                self.logger.info(
                    f"ğŸ åŠ å…¥è½®æ¬¡: {round_num} ä»é˜¶æ®µ: {stage} å¼€å§‹"
                )
                try:
                    self.train_stages(round_num, stage, is_coordinator=False)
                except datasets.exceptions.DatasetGenerationError:
                    if stage > 0:
                        self.logger.info("å°è¯•ä»é˜¶æ®µ0é‡æ–°å¼€å§‹è®­ç»ƒï¼")

                        # ä»é˜¶æ®µ0é‡æ–°å¼€å§‹
                        self.train_stages(round_num, 0, is_coordinator=False)
                    else:
                        raise

                done_rounds.add(round_num)
                check_backoff = check_interval  # æˆåŠŸè½®æ¬¡åé‡ç½®é€€é¿
            else:
                if check_backoff != 30:
                    self.logger.info(
                        f":{self.node.key}:å·²å®Œæˆè®­ç»ƒè½®æ¬¡: {round_num}ã€‚å°†åœ¨ {check_backoff}ç§’ åé‡æ–°æ£€æŸ¥æ˜¯å¦æœ‰æ–°ä»»åŠ¡ï¼Œæ—¥å¿—æš‚åœåˆ·æ–°ï¼Œä¸æ˜¯å¡ä½ï¼Œè€å¿ƒç­‰å¾…ã€‚"
                    )
                time.sleep(check_backoff)
                check_backoff = min(check_backoff * 2, max_check_interval)

            if round_num == self.stage_data.max_rounds - 1:
                return

        self.logger.info("è®­ç»ƒè¶…æ—¶ï¼")

    def _train(self):
        """è®­ç»ƒå…¥å£æ–¹æ³•ï¼Œæ ¹æ®èŠ‚ç‚¹è§’è‰²é€‰æ‹©é€‚å½“çš„è®­ç»ƒæ–¹æ³•"""
        if self.node.is_coordinator:
            self.coordinator_train()
        else:
            self.follower_train()

    def train(self):
        """è®­ç»ƒæ–¹æ³•ï¼Œæ•è·å¹¶å¤„ç†è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¼‚å¸¸"""
        try:
            self._train()

        except Exception:
            self.logger.error("è®­ç»ƒè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯ï¼")
            print_system_info()
            traceback.print_exc()
            raise
